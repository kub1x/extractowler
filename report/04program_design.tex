\label[chap:design]
\chap Program design

This chapter defines the overall behavior of the program derived from
requiroments as well as the proposed design. 

\sec Workflow

Derived from previous use case definitions we can derive the general workflow
for both SOWL and crOWLer part of the implementation. 

\secc Main line

\begitems
  * user loads/creates ontology using sowl
  * user opens webpage with data
  * user creates scenario using sowl
  \begitems
    * user adds selectors to scenario steps
    * user adds resources to scenario steps
  \enditems
  * sowl sends scenario to crOWLer
  * crOWLer crawls the web according to scenario and stores results in a file
    or repository
\enditems


\secc Scenario creation

\begitems
  * user starts scenario creation in sowl
  * loop until finished:
  \begitems
    * user creates a step in scenarion
    * user selects an element on page, a selector is generated if applicable,
      on the step
    * user selects a resource, resource is updated on the appropriate field of
      the step, if applicable
  \enditems
\enditems


\secc Additional branches to Scenario Creation

\begitems
  * user can navigate through scenario by clicking scenario steps
  * user can navigate through scenario by clicking ontological context
  * user can navigate through scenario by clicking areas on webpage covered by scenario
  * when user clicks on a hyperlink: 
  \begitems
    * existing template can be assigned to the action (no need to actually
      follow the link)
    * new tamplete can be created for resulting action (resulting page loaded,
      new template created)
  \enditems
\enditems

\secc crOWLer scraping

\begitems
  * user runs crOWLer passing it the created scenario
  * crOWLer parses the scenario
  * crOWLer scrapes data from the webpage following the scenario
  * crOWLer stores the results in file or repository
\enditems


\sec User Interface

Here the required stucture of user interface is described. 

\secc SOWL user interface

The user interface of SOWL shall be presented in a form of sidebar. The sidebar
shall have two parts: a scenario editor and resources list. Scenario editor
shall contain a tree shaped structure of steps of the scenario being created
along with panel for editing the general settings of the scenario. The
resources list shall accept dropping of ontology files which would load it into
current dataset. Addition of resources manually shall be possible using a
button. The list shall show all currently loaded resources and allow textual
filtering. 

SOWL shall enable tag selection on the webpage being processed by clicking or
other user action. 


\secc crOWLer user interface

crOWLer is a console application. It shall accept scenario as one of it's parameters. 
Following settings shall be enabled using parameters as well:
\begitems
  * setting of target directory for RDF files
  * setting of sesame repository for the result storage
\enditems


\sec Model

Presenting proposed design of the two programs the SOWL Firefox addon and the
crOWLer Java application. 

\secc SOWL model

Current recommendation of Mozilla Developer Network suggests developing new
addons using their native SDK. It allows creation of restartless addons, uses 
new API and limits usage of older libraries or low level calls by wrapping it 
in consistent API. 

The SDK based addons have partially predefined structure. The {\em background script}
runs in it's own scope and uses the SDK API to controll the addon's behavior.
The {\em content script} is a javascript code that is injected into a webpage
but runs in it's own sandboxed overlay, while having access to pages DOM and
javascript content. In SOWL, the scenario editor will be placed into a sidebar.
Sidebar holds standard HTML window object in which the javascript code is
running.  All three components communicate via textual messages using {\tt
port} object offered internally by by Firefox. 

\midinsert
\picw=12.5cm \cinspic sowl-components.png
\caption/f A component structure of the SOWL firefox addon. 
\endinsert


\secc crOWLer model

In the new implementation of the scraping backend the original JSOUP component
will be replaced by WebDriver. WebDriver, with it's support for javascript,
will help to handle dynamic content and brings in new possibilities for the
crOWLer itself. The original configuration component is replaced by parser for
the SOWL/JSON scenario format (XXX ref).  The core crOWLer is also
reimplemented according to new set of instructions (i.e. commands in the
scenario) and the new web interface (i.e. the WebDriver instead of the native
Java Jsoup library). 

The overall architecture then looks as follows: 

\midinsert
\picw=7.5cm \cinspic crowler-new.png
\caption/f A new overall architecture of the crOWLer implementation. 
\endinsert



%TODO
%\sec Issues - solved and unsolved
%
%\begitems
%  * error handling (non existent selector, missing data, ...)
%\enditems

% * diagramy... clas, sequence (komunikace s jOWLem, komunikace s generatorem selectoru, ), 
% * model
% * vyresene, nevyresene problemy




