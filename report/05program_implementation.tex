\label[chap:implementation] 
\chap Program Implementation and Specifications

This chapter describes the implemented prototype of SOWL--crOWLer tool stack. 
The relation between tools can be seen on diagram \ref[pic:sowl-crowler-stack]. 

\midinsert \clabel[pic:sowl-crowler-stack]{Overview of the whole stack and files exchanged}
\picw=14cm \cinspic sowl-crowler-stack.png
\caption/f Overview of the whole stack and files exchanged
\endinsert

\sec SOWL implementation

During testing of various technologies and frameworks several prototypes of the 
scenario creator was built. The first one called SelectOWL was native Firefox
addon build on XUL and calls to Firefox low level API. Development of SelectOWL
was discontinued in favour of new addon with shortened name SOWL. The new 
addon is based on Firefox addon SDK. The structure of the addon is completely 
different from the original one and the JavaScript of the addon runs in
different context too. The new SDK is the recommended approach now and offers
more flexible functionality and more intuitive code structure as the user
interface is defined using classical HTML instead of XUL. The original version
is kept in the repository for reference
\urlnote{https://github.com/kub1x/selectowl/tree/master/ff-extension}. 


\secc Parsing Ontologies in JavaScript

Both jOWL vs rdfQuery were tested on common ontologies (FOAF, Dublin Core, Good
Relations). Results shown that the newer rdfQuery library more accurately implements
the standard behavior for handling RDF resources.

Specifically in jOWL all resources have only one type. This type is determined
when parsing input XML fileby a lookup cascade: if the type is not determined
by the explicit RDF type property, the parser would look into the overlying tag
name. 

rdfQuery, on the other hand, properly stores all the data in form of triples in its 
internal dataset implementation. By using this approach it offers correct results
and is our library of choice. 

Even though rdfQuery currently serves for parsing of input files only, we might
consider utilizing its reasoning capabilities in future development. 


\secc Targeting elements on webpage and generating selectors

\midinsert \clabel[pic:selector-creation]{Diagram of selector creation algorithm}
\picw=7cm \cinspic selector-creation.png
\caption/f Diagram of selector creation algorithm 
\endinsert

Inspired by the InfoCram project we decided to use Aardvark code in order to 
target elements on webpage and obtain their selectors. 

In early stages the native addon code for Aardvark was used. Unfortunately this
code uses some internal Firefox API and had to be replaced when new Firefox SDK
was used for the SOWL development. 

In current Implementation of SOWL we create different type of Firofox extension
using new SDK. Moreover the aardvark code is injected directly into the webpage
using the Content Script feature of the Firefox SDK. According to these
differences the bookmarklet version better fits the needs and is used. The
aardvark code is included in the addon files extended with features necessary
for SOWL. Namely the event handling was extended by drag/drop events and 
selector creation algorithm was added. 

Even though it was rewritten it behaves almost identically as in
InfoCram. We simply bubble up the DOM tree until we meet our context. On each
element we try to generate unique selector according to the elements parent
element. The last method to try is the {\tt :nth-child()} selector which always
exists and targets the correct element, but is also most prone to failures due
tu structure changes. If possible ID or class attributes are used to target the
element. 

As use case 2 \ref[sec:intro:uc2] shown we can not always rely on class selectors as they are 
often dynamically modified by pages JavaScript. For this reason the class
selector are disabled by default, but they are supported by crOWLer and can be
manually specified in the selector field. Aardvark shows the class of a hovered
element on its label to simplify this task. 


\sec crOWLer implementation

The current implementation of crOWLer forms the architecture on picture
\ref[pic:crowler-new-overall]. Even though the overall architecture holds
visually the similar structure as the original implementation, the result is 
technically brand new program. Change from configuration system to scenario
changed the input handling and influenced structure of the core algorithm 
from loop-based to template-based. The main library for web communication 
was changed from JSOUP to WebDriver which combined with scenario led to 
complete reimplementation of the core. The only part derived from original
crOWLer are the Jena and JenaSesame libraries for handling the ontological
models and storage of RDF data. The complete architecture can be better seen on
the component model in appendix \label[app:crowler-new-component]. 

\midinsert \clabel[pic:crowler-new-overall]{The overall architecture of new crOWLer implementation}
\picw=12cm \cinspic crowler-new.png
\caption/f The overall architecture of new crOWLer implementation
\endinsert

%Scenario based on Strigil/XML syntax (or its JSON alternative) is not directly 
%translatable into the original crOWLer configuration. 
%
%XXX example of Strigil XML that can not be parsed into crOWLer configuration

A new structure was implemented holding a Scenario object with its steps.  In
this form the Scenario is passed to main loop. Instead of {\tt FullCrawler}
based on JSOUP we created WebDriver based solution, the {\tt WebDriverCrawler}. 


\sec SOWL/JSON syntax

Following is the final list of commands proposed for crOWLer implementation.
Only a subset is implemented in the prototype. Each command is described and
its attributes are listed (also with description). 


\secc template %%%

Command defining a list of steps to be performed on document passed to it. 
\begitems
  * name -- name identifying the template (referenced by call-template command)
  * steps -- list of steps of the template
\enditems


\secc call-template %%%

Command used to call a template. If no URL is specified template shall be
called on current context. 
\begitems
  * name -- name identifying the template to be called
  * values -- defines list of commands; every command returns an URL;
    the targeted template will be called on each URL
  * value -- same as previous, only contains a single command
  * selector -- URL will be taken from text of elements matched by this selector
  * attribute -- URL will be taken from this attribute of elements matched by previous selector
  * url -- default URL if one of the previous returns a value 
\enditems


\secc onto-elem

Creates an ontological individual. 
\begitems
  * about -- contains a command returning URI identifying the newly created individual
  * typeof -- contains the rdf:type of the individual
  * rel -- contains an URI of Object Property; the individual is assigned to this property of his parent
  * selector -- the individual is created for each element matching this selector
  * steps -- list of subcommands; they will be executed in context of this individual
            and the selected HTML element
\enditems


\secc value-of

Returns a string value or assigns it to a data property. 
\begitems
  * selector -- returns a value of text content of the first element specified by this attribute
  * attribute -- if specified a value of this attribute of the selected element is specified
  * text -- a constant string; is returned if none of the previous targets a non-null value
  * property -- the resulting value is assigned to this property of parent
  individual, rather than returned; in combination with selector the values of all
  targeted elements are assigned
  * lang -- a language tag appended to the string before assigned as a property
  * type -- a datatype appended to the string  before assigned as a property
  * exec -- a JavaScript function applied to the string before it is returned
\enditems


\secc narrow

This tag only narrows the HTML context to simplify selectors in child steps. 
\begitems
  * steps -- set of steps to be called on narrowed context
  * select -- inner steps will be called on each of these elements
  * exec -- call JavaScript function on a set of elements to filter them
\enditems

\secc function

Calls a predefined function
\begitems
  * name -- name of the called function one of following: 
  \begitems
    * conc -- concatenate all strings into one
    * join -- similar to previous; inserts the first string between all the other ones when connecting
    * parseDate -- takes date format string as a first parameter and date to be parsed as second; 
              it returns the parsed date in xsd:Date or null
    * uuid -- takes no parameters, returns a new UUID
    * currentUrl -- takes no parameters, returns a URL of current document
  \enditems
  * params -- an array of commands returning values used as parameters for the function call
\enditems


